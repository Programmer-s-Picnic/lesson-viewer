<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Face Detection Stage-1 PRO (Mobile)</title>
    <meta name="theme-color" content="#f59e0b" />

    <style>
      :root {
        --bg: #fff7e6;
        --card: #ffffffcc;
        --ink: #1f2937;
        --muted: #6b7280;
        --brand: #d97706;
        --brand2: #f59e0b;
        --border: #eadcc5;
        --shadow: 0 18px 40px rgba(31, 41, 55, 0.14);
        --r: 18px;
        --sans:
          ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica,
          Arial;
        --mono:
          ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas,
          "Liberation Mono", "Courier New", monospace;
      }
      * {
        box-sizing: border-box;
      }
      body {
        margin: 0;
        font-family: var(--sans);
        color: var(--ink);
        background:
          radial-gradient(
            900px 520px at 15% 10%,
            rgba(245, 158, 11, 0.22),
            transparent 60%
          ),
          radial-gradient(
            900px 520px at 85% 0%,
            rgba(217, 119, 6, 0.18),
            transparent 60%
          ),
          var(--bg);
      }
      .wrap {
        max-width: 1050px;
        margin: 0 auto;
        padding: 14px;
      }
      .top {
        display: flex;
        align-items: center;
        justify-content: space-between;
        gap: 10px;
        padding: 10px 12px;
        border-radius: 999px;
        background: rgba(255, 247, 230, 0.72);
        border: 1px solid rgba(234, 220, 197, 0.95);
        box-shadow: 0 10px 24px rgba(31, 41, 55, 0.1);
        position: sticky;
        top: 0;
        z-index: 5;
        backdrop-filter: blur(10px);
        flex-wrap: wrap;
      }
      .title {
        display: flex;
        align-items: center;
        gap: 10px;
      }
      .logo {
        width: 34px;
        height: 34px;
        border-radius: 12px;
        background: linear-gradient(135deg, var(--brand), var(--brand2));
        box-shadow: 0 12px 26px rgba(217, 119, 6, 0.28);
      }
      h1 {
        margin: 0;
        font-size: 14px;
        line-height: 1.1;
      }
      .sub {
        font-size: 12px;
        color: var(--muted);
        margin-top: 2px;
      }
      .pill {
        font-size: 12px;
        padding: 6px 10px;
        border-radius: 999px;
        background: rgba(245, 158, 11, 0.16);
        border: 1px solid rgba(217, 119, 6, 0.22);
        color: #92400e;
        white-space: nowrap;
      }
      .card {
        margin-top: 12px;
        background: var(--card);
        border: 1px solid rgba(234, 220, 197, 0.95);
        border-radius: var(--r);
        box-shadow: var(--shadow);
        overflow: hidden;
      }
      .card-h {
        padding: 12px 12px 10px 12px;
        border-bottom: 1px solid rgba(234, 220, 197, 0.8);
        display: flex;
        align-items: center;
        justify-content: space-between;
        gap: 10px;
        flex-wrap: wrap;
      }
      .btn {
        border-radius: 12px;
        border: 1px solid rgba(234, 220, 197, 0.95);
        background: #fff;
        padding: 10px 12px;
        font-size: 13px;
        cursor: pointer;
        box-shadow: 0 10px 22px rgba(31, 41, 55, 0.08);
        user-select: none;
      }
      .btn.primary {
        background: linear-gradient(135deg, var(--brand), var(--brand2));
        color: #fff;
        border-color: rgba(217, 119, 6, 0.35);
        box-shadow: 0 14px 30px rgba(217, 119, 6, 0.22);
      }
      .btn:disabled {
        opacity: 0.55;
        cursor: not-allowed;
      }
      .controls {
        padding: 12px;
        display: flex;
        gap: 10px;
        flex-wrap: wrap;
        align-items: center;
      }
      .toggle {
        display: flex;
        align-items: center;
        gap: 8px;
        padding: 8px 10px;
        border-radius: 14px;
        border: 1px solid rgba(234, 220, 197, 0.95);
        background: rgba(255, 255, 255, 0.75);
        font-size: 12px;
        color: var(--ink);
      }
      .toggle input {
        transform: scale(1.15);
      }
      .stage {
        position: relative;
        background: #0b1220;
        border-radius: 16px;
        overflow: hidden;
      }
      video {
        width: 100%;
        height: auto;
        display: block;
        transform: scaleX(-1);
      }
      canvas {
        position: absolute;
        inset: 0;
        width: 100%;
        height: 100%;
        pointer-events: none;
      }
      .hud {
        position: absolute;
        left: 10px;
        top: 10px;
        background: rgba(255, 255, 255, 0.14);
        border: 1px solid rgba(245, 158, 11, 0.22);
        backdrop-filter: blur(10px);
        padding: 8px 10px;
        border-radius: 14px;
        color: #fff;
        font-size: 12px;
        display: flex;
        gap: 10px;
        align-items: center;
        flex-wrap: wrap;
      }
      .hud b {
        font-family: var(--mono);
        font-weight: 700;
      }
      .note {
        margin: 12px;
        padding: 10px 12px;
        border-radius: 14px;
        border: 1px solid rgba(245, 158, 11, 0.35);
        background: rgba(245, 158, 11, 0.14);
        color: #7c2d12;
        font-size: 12px;
      }
      .range {
        display: flex;
        align-items: center;
        gap: 8px;
      }
      input[type="range"] {
        width: 160px;
      }
    </style>

    <!-- Face API (vladmandic fork) -->
    <script
      defer
      src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1/dist/face-api.js"
    ></script>
  </head>
  <body>
    <div class="wrap">
      <div class="top">
        <div class="title">
          <div class="logo" aria-hidden="true"></div>
          <div>
            <h1>Face Detection Stage-1 PRO</h1>
            <div class="sub">FPS • Face Count • Switch Cam • Pinch Zoom</div>
          </div>
        </div>
        <span class="pill" id="status">Loading models…</span>
      </div>

      <div class="card">
        <div class="card-h">
          <div class="sub" style="margin: 0">Use HTTPS Only</div>
          <div style="display: flex; gap: 10px; flex-wrap: wrap">
            <button class="btn primary" id="startBtn" disabled>Start</button>
            <button class="btn" id="stopBtn" disabled>Stop</button>
            <button class="btn" id="switchBtn" disabled>Switch Camera</button>
          </div>
        </div>

        <div class="controls">
          <label class="toggle" title="Mirror video for front camera feel">
            <input type="checkbox" id="mirror" checked /> Mirror
          </label>

          <label
            class="toggle"
            title="Detection strictness (higher = fewer false positives)"
          >
            <span style="color: #6b7280">Score ≥</span>
            <select id="score" class="btn" style="padding: 8px 10px">
              <option value="0.35">0.35 (loose)</option>
              <option value="0.5" selected>0.50 (default)</option>
              <option value="0.65">0.65 (strict)</option>
            </select>
          </label>

          <label
            class="toggle"
            title="Detection frequency (lower = faster, less accurate)"
          >
            <span style="color: #6b7280">Detect ms</span>
            <select id="detectEvery" class="btn" style="padding: 8px 10px">
              <option value="80">80</option>
              <option value="120">120</option>
              <option value="160" selected>160</option>
              <option value="220">220</option>
              <option value="300">300</option>
            </select>
          </label>

          <div
            class="toggle range"
            id="zoomWrap"
            style="display: none"
            title="Camera zoom (if supported)"
          >
            <span style="color: #6b7280">Zoom</span>
            <input
              type="range"
              id="zoom"
              min="1"
              max="1"
              step="0.1"
              value="1"
            />
            <span id="zoomVal" style="font-family: var(--mono); font-size: 12px"
              >1.0×</span
            >
          </div>
        </div>

        <div class="stage" id="stage">
          <video id="video" playsinline muted></video>
          <canvas id="overlay"></canvas>

          <div class="hud">
            <span>FPS: <b id="fps">0</b></span>
            <span>Faces: <b id="faces">0</b></span>
            <span>Cam: <b id="cam">user</b></span>
          </div>
        </div>

        <div class="note">Select back and front camera.</div>
      </div>
    </div>

    <script>
      (() => {
        const MODEL_BASE =
          "https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.15/model/";

        const video = document.getElementById("video");
        const canvas = document.getElementById("overlay");
        const statusEl = document.getElementById("status");

        const startBtn = document.getElementById("startBtn");
        const stopBtn = document.getElementById("stopBtn");
        const switchBtn = document.getElementById("switchBtn");

        const mirrorCb = document.getElementById("mirror");
        const scoreSel = document.getElementById("score");
        const detectEverySel = document.getElementById("detectEvery");

        const fpsEl = document.getElementById("fps");
        const facesEl = document.getElementById("faces");
        const camEl = document.getElementById("cam");

        const zoomWrap = document.getElementById("zoomWrap");
        const zoomRange = document.getElementById("zoom");
        const zoomVal = document.getElementById("zoomVal");

        let stream = null;
        let running = false;
        let rafId = null;

        // current facing mode
        let facing = "user"; // "user" or "environment"

        // detection throttle
        let lastDetectAt = 0;
        let lastDetections = [];

        // fps calc
        let frames = 0;
        let lastFpsAt = performance.now();

        function setStatus(txt) {
          statusEl.textContent = txt;
        }

        function setMirror(on) {
          video.style.transform = on ? "scaleX(-1)" : "none";
        }
        mirrorCb.addEventListener("change", () => setMirror(mirrorCb.checked));
        setMirror(true);

        function resizeCanvas() {
          const w = video.videoWidth || video.clientWidth;
          const h = video.videoHeight || video.clientHeight;
          if (!w || !h) return;
          if (canvas.width !== w) canvas.width = w;
          if (canvas.height !== h) canvas.height = h;
        }

        function tinyOptions() {
          return new faceapi.TinyFaceDetectorOptions({
            inputSize: 320,
            scoreThreshold: Number(scoreSel.value || 0.5),
          });
        }

        async function loadModels() {
          setStatus("Loading models…");
          for (let i = 0; i < 80; i++) {
            if (window.faceapi) break;
            await new Promise((r) => setTimeout(r, 50));
          }
          if (!window.faceapi)
            throw new Error("face-api failed to load (CDN blocked/offline).");

          await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_BASE);
          setStatus("Models loaded ✓ Tap Start");
          startBtn.disabled = false;
        }

        async function start() {
          if (running) return;
          try {
            setStatus("Requesting camera…");

            stream = await navigator.mediaDevices.getUserMedia({
              video: { facingMode: facing },
              audio: false,
            });

            video.srcObject = stream;
            await video.play();
            resizeCanvas();
            window.addEventListener("resize", resizeCanvas);

            running = true;
            startBtn.disabled = true;
            stopBtn.disabled = false;
            switchBtn.disabled = false;

            camEl.textContent = facing;
            setStatus("Running ✓ Box should appear");

            // setup zoom slider if supported
            await setupZoom();

            loop();
          } catch (err) {
            setStatus("Camera blocked ✗");
            alert(
              "Camera did not start.\n\nFix:\n1) Use HTTPS (GitHub Pages) or localhost.\n2) Allow camera permission.\n3) Close other apps using camera.\n\nDetails: " +
                (err?.message || err),
            );
          }
        }

        function stop() {
          running = false;
          if (rafId) cancelAnimationFrame(rafId);
          rafId = null;

          if (stream) {
            stream.getTracks().forEach((t) => t.stop());
            stream = null;
          }
          video.srcObject = null;

          const ctx = canvas.getContext("2d");
          ctx.clearRect(0, 0, canvas.width, canvas.height);

          startBtn.disabled = false;
          stopBtn.disabled = true;
          switchBtn.disabled = true;

          zoomWrap.style.display = "none";

          facesEl.textContent = "0";
          fpsEl.textContent = "0";
          setStatus("Stopped");
        }

        async function restartWithFacing(newFacing) {
          facing = newFacing;
          camEl.textContent = facing;
          if (!running) return;
          stop();
          await new Promise((r) => setTimeout(r, 120));
          await start();
        }

        // Switch camera without reloading page
        switchBtn.addEventListener("click", async () => {
          const next = facing === "user" ? "environment" : "user";
          await restartWithFacing(next);
          // Mirror default: on for user cam, off for environment cam (you can still toggle manually)
          if (next === "environment") mirrorCb.checked = false;
          if (next === "user") mirrorCb.checked = true;
          setMirror(mirrorCb.checked);
        });

        startBtn.addEventListener("click", start);
        stopBtn.addEventListener("click", stop);

        // Pinch-to-zoom via slider + capabilities
        async function setupZoom() {
          zoomWrap.style.display = "none";
          zoomRange.oninput = null;

          const track = stream?.getVideoTracks?.()[0];
          if (!track) return;

          // Some browsers support getCapabilities; others don’t.
          const caps = track.getCapabilities ? track.getCapabilities() : null;
          if (!caps || caps.zoom == null) return;

          const { min, max, step } = caps.zoom;
          zoomRange.min = String(min);
          zoomRange.max = String(max);
          zoomRange.step = String(step || 0.1);

          // current zoom from settings if available
          const settings = track.getSettings ? track.getSettings() : {};
          const current = settings.zoom || 1;
          zoomRange.value = String(current);
          zoomVal.textContent = Number(current).toFixed(1) + "×";

          zoomWrap.style.display = "flex";

          zoomRange.oninput = async () => {
            const z = Number(zoomRange.value);
            zoomVal.textContent = z.toFixed(1) + "×";
            try {
              await track.applyConstraints({ advanced: [{ zoom: z }] });
            } catch (e) {
              // ignore if not supported at runtime
            }
          };

          // Optional: pinch gesture to move zoom slider
          enablePinchZoom(zoomRange, Number(min), Number(max));
        }

        function enablePinchZoom(rangeEl, min, max) {
          // Pinch on the video/stage to set zoom (works only if slider exists)
          const stage = document.getElementById("stage");
          let startDist = null;
          let startVal = null;

          stage.ontouchstart = (e) => {
            if (zoomWrap.style.display === "none") return;
            if (e.touches.length === 2) {
              startDist = touchDist(e.touches[0], e.touches[1]);
              startVal = Number(rangeEl.value);
            }
          };
          stage.ontouchmove = (e) => {
            if (zoomWrap.style.display === "none") return;
            if (e.touches.length === 2 && startDist != null) {
              e.preventDefault();
              const d = touchDist(e.touches[0], e.touches[1]);
              const ratio = d / startDist;
              // scale zoom by ratio, clamp
              let next = startVal * ratio;
              next = Math.max(min, Math.min(max, next));
              // set and trigger input
              rangeEl.value = String(next);
              rangeEl.dispatchEvent(new Event("input"));
            }
          };
          stage.ontouchend = () => {
            startDist = null;
            startVal = null;
          };

          function touchDist(a, b) {
            const dx = a.clientX - b.clientX;
            const dy = a.clientY - b.clientY;
            return Math.hypot(dx, dy);
          }
        }

        // Main loop: draw every frame, detect faces only every N ms
        async function loop() {
          if (!running) return;

          resizeCanvas();
          const ctx = canvas.getContext("2d");
          ctx.clearRect(0, 0, canvas.width, canvas.height);

          // FPS
          frames++;
          const now = performance.now();
          if (now - lastFpsAt >= 500) {
            const fps = Math.round((frames * 1000) / (now - lastFpsAt));
            fpsEl.textContent = String(fps);
            frames = 0;
            lastFpsAt = now;
          }

          // Throttled detection
          const detectEvery = Number(detectEverySel.value || 160);
          if (now - lastDetectAt >= detectEvery) {
            lastDetectAt = now;
            try {
              lastDetections = await faceapi.detectAllFaces(
                video,
                tinyOptions(),
              );
              facesEl.textContent = String(lastDetections.length);
            } catch (e) {
              // ignore occasional detection errors
            }
          }

          // Draw mirrored overlay if video is mirrored
          ctx.save();
          if (mirrorCb.checked) {
            ctx.translate(canvas.width, 0);
            ctx.scale(-1, 1);
          }

          ctx.lineWidth = 3;
          ctx.strokeStyle = "rgba(245,158,11,.95)";
          ctx.fillStyle = "rgba(245,158,11,.12)";

          for (const d of lastDetections) {
            const b = d.box;
            roundRect(ctx, b.x, b.y, b.width, b.height, 10, true, true);
          }

          ctx.restore();
          rafId = requestAnimationFrame(loop);
        }

        function roundRect(ctx, x, y, w, h, r, fill, stroke) {
          const rr = Math.min(r, w / 2, h / 2);
          ctx.beginPath();
          ctx.moveTo(x + rr, y);
          ctx.arcTo(x + w, y, x + w, y + h, rr);
          ctx.arcTo(x + w, y + h, x, y + h, rr);
          ctx.arcTo(x, y + h, x, y, rr);
          ctx.arcTo(x, y, x + w, y, rr);
          ctx.closePath();
          if (fill) ctx.fill();
          if (stroke) ctx.stroke();
        }

        // Init
        if (!navigator.mediaDevices?.getUserMedia) {
          setStatus("Browser unsupported ✗");
          alert(
            "This browser does not support camera access. Try Chrome on Android.",
          );
          return;
        }

        loadModels().catch((err) => {
          setStatus("Model load failed ✗");
          alert(
            "Models could not be loaded.\n\nPossible reasons:\n- No internet / CDN blocked\n- Adblock blocks jsdelivr\n\nDetails: " +
              (err?.message || err),
          );
        });
      })();
    </script>
  </body>
</html>
